<p align="center">
  <h1 align="center">ğŸ“° Nuze</h1>
  <p align="center">
    <strong>AI-Powered Personalized News Aggregator</strong>
  </p>
  <p align="center">
    A full-stack application that collects news from multiple sources, synthesizes articles using LLM, and delivers a personalized news feed that learns from your preferences.
  </p>
</p>

---

## âœ¨ Features

- **ğŸ¤– AI-Synthesized Articles** â€” Combines multiple news sources into unified, balanced articles using local LLM
- **ğŸ¯ Personalized Feed** â€” Vector-based recommendation using pgvector similarity matching
- **ğŸ“š Preference Learning** â€” User preferences evolve based on interactions (likes/dislikes)
- **ğŸ“ Daily Summaries** â€” LLM-generated personalized news digests
- **ğŸ” JWT Authentication** â€” Secure user registration and login
- **ğŸ“Š 10 News Categories** â€” Politics, Economy, Science, Health, Education, Culture, Religion, Sports, World Affairs, Opinion

---

## ğŸ—ï¸ Architecture

```mermaid
flowchart TB
    subgraph Client["Client Application"]
        WEB["React + Vite"]
    end

    subgraph Backend["FastAPI Backend"]
        API["REST API"]
        SCHEDULER["APScheduler"]
    end

    subgraph AI["AI/ML Layer"]
        OLLAMA["Ollama LLM"]
        MODELS["Custom Models"]
    end

    subgraph Data["Data Layer"]
        DB[("PostgreSQL + pgvector")]
        SCRAPERS["News Scrapers"]
    end

    WEB --> API
    API --> DB
    SCHEDULER --> SCRAPERS
    SCHEDULER --> OLLAMA
    SCRAPERS --> DB
    OLLAMA --> DB
    API --> OLLAMA
```

---

## ğŸ› ï¸ Tech Stack

### Backend
| Technology | Purpose |
|------------|---------|
| **FastAPI** | REST API framework |
| **PostgreSQL + pgvector** | Database with vector similarity search |
| **SQLAlchemy 2.0** | Async ORM |
| **Ollama** | Local LLM inference |
| **APScheduler** | Background task scheduling |
| **Passlib + python-jose** | Authentication (bcrypt + JWT) |

### Frontend
| Technology | Purpose |
|------------|---------|
| **React 19** | UI framework |
| **Vite** | Build tool & dev server |
| **React Router** | Client-side routing |
| **Axios** | HTTP client |

### DevOps
| Technology | Purpose |
|------------|---------|
| **Docker Compose** | Container orchestration |
| **uv** | Python package management |
| **Pytest** | Testing framework |
| **Locust** | Load testing |

---

## ğŸ“ Project Structure

```
nuze-backend/
â”œâ”€â”€ app/                          # FastAPI application
â”‚   â”œâ”€â”€ main.py                   # Application entrypoint
â”‚   â”œâ”€â”€ database.py               # Database configuration
â”‚   â”œâ”€â”€ models/                   # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ user.py               # User entity
â”‚   â”‚   â”œâ”€â”€ article.py            # Raw article entity
â”‚   â”‚   â”œâ”€â”€ synthesized_article.py # AI-generated articles
â”‚   â”‚   â”œâ”€â”€ interaction.py        # User interactions
â”‚   â”‚   â””â”€â”€ summary.py            # Daily summaries
â”‚   â”œâ”€â”€ routers/                  # API endpoints
â”‚   â”‚   â”œâ”€â”€ auth.py               # /auth - Authentication
â”‚   â”‚   â”œâ”€â”€ users.py              # /me - User management
â”‚   â”‚   â”œâ”€â”€ feed.py               # /feed - Personalized feed
â”‚   â”‚   â”œâ”€â”€ summary.py            # /summary - Daily summaries
â”‚   â”‚   â”œâ”€â”€ feedback.py           # /feedback - Preference updates
â”‚   â”‚   â”œâ”€â”€ interactions.py       # /interactions - Like/dislike
â”‚   â”‚   â””â”€â”€ ingestion.py          # /ingest - Manual triggers
â”‚   â”œâ”€â”€ services/                 # Business logic
â”‚   â”‚   â”œâ”€â”€ nlp_service.py        # LLM integration
â”‚   â”‚   â”œâ”€â”€ feed_service.py       # Feed generation
â”‚   â”‚   â”œâ”€â”€ feedback_service.py   # Preference learning
â”‚   â”‚   â”œâ”€â”€ ingestion_service.py  # Article ingestion
â”‚   â”‚   â”œâ”€â”€ summary_service.py    # Summary generation
â”‚   â”‚   â””â”€â”€ scheduler.py          # Background tasks
â”‚   â””â”€â”€ schemas/                  # Pydantic models
â”œâ”€â”€ frontend/                     # React application
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/           # React components
â”‚       â”‚   â”œâ”€â”€ Article.jsx       # Article display
â”‚       â”‚   â”œâ”€â”€ DailySummary.jsx  # Summary view
â”‚       â”‚   â”œâ”€â”€ Onboarding.jsx    # Category selection
â”‚       â”‚   â”œâ”€â”€ Preferences.jsx   # Preference visualization
â”‚       â”‚   â””â”€â”€ Profile.jsx       # User settings
â”‚       â””â”€â”€ api.js                # API client
â”œâ”€â”€ scrapers/                     # News source scrapers
â”‚   â”œâ”€â”€ new_bbc_scraper.py
â”‚   â”œâ”€â”€ new_cnn_scraper.py
â”‚   â”œâ”€â”€ new_foxnews_scraper.py
â”‚   â”œâ”€â”€ new_nytimes_scraper.py
â”‚   â””â”€â”€ new_sky_news_scraper.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init/                     # Initialization scripts
â”‚   â”‚   â”œâ”€â”€ init.sql              # Database extensions
â”‚   â”‚   â”œâ”€â”€ init_ollama.sh        # Ollama setup
â”‚   â”‚   â””â”€â”€ ollama-models/        # Custom LLM models
â”‚   â”œâ”€â”€ daily_cluster.py          # Article synthesis job
â”‚   â””â”€â”€ daily_ingest.py           # Article ingestion job
â”œâ”€â”€ tests/                        # Test suites
â”œâ”€â”€ docs/                         # Documentation
â””â”€â”€ docker-compose.yml            # Container orchestration
```

---

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- NVIDIA GPU (for Ollama, optional but recommended)

### 1. Clone & Start

```bash
git clone <repository-url>
cd nuze-backend
docker compose up -d
```

### 2. Access the Application

| Service | URL |
|---------|-----|
| Frontend | http://localhost:5173 |
| Backend API | http://localhost:8000 |
| API Docs | http://localhost:8000/docs |
| Ollama | http://localhost:11434 |

### 3. Initial Setup

On first run, the system will:
1. Initialize PostgreSQL with pgvector extension
2. Pull and configure Ollama models (phi4 base + custom models)
3. Create database tables via SQLAlchemy

---

## ğŸ”„ Data Flow

### 1. Content Ingestion
```
News Sources â†’ Scrapers â†’ NLP Classification â†’ Articles DB
```
Scheduled task scrapes articles from 5 news sources, classifies them into a 10-dimensional category vector using LLM.

### 2. Article Synthesis
```
Similar Articles â†’ Clustering â†’ LLM Synthesis â†’ SynthesizedArticles DB
```
Daily job groups similar articles and generates balanced, unified articles.

### 3. Feed Generation
```
User Request â†’ Vector Similarity (user preferences â†” article categories) â†’ Ranked Feed
```
Uses pgvector's cosine similarity to match user preferences with article category vectors.

### 4. Preference Learning
```
User Interaction â†’ Feedback Service â†’ Vector Update â†’ User Preferences
```
Likes/dislikes adjust the user's 10-dimensional preference vector to improve future recommendations.

---

## ğŸ§  Custom LLM Models

Three custom Ollama models built on phi4:

| Model | Purpose |
|-------|---------|
| `news-classifier` | Classifies articles into 10 categories with confidence scores |
| `news-combiner` | Synthesizes multiple articles into a unified piece |
| `news-summarizer` | Generates personalized daily summaries |

---

## ğŸ“° News Categories

The system uses 10 categories for article classification and user preferences:

1. Politics & Law
2. Economy & Business
3. Science & Technology
4. Health & Wellness
5. Education & Society
6. Culture & Entertainment
7. Religion & Belief
8. Sports
9. World & International Affairs
10. Opinion & General News

---

## ğŸ§ª Testing

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=app

# Run specific test file
uv run pytest tests/unit/test_nlp_service.py
```

### Load Testing
```bash
cd tests/load
locust -f locustfile.py
```

---

## ğŸ“Š Evaluation

Generate offline evaluation metrics for the recommendation system:

```bash
python experiments/evaluation_report.py
```

Outputs `experiments/evaluation_report.md` with per-user and aggregate metrics.

---

## ğŸ”§ Development

### Running Locally (without Docker)

```bash
# Backend
uv sync
uv run uvicorn app.main:app --reload

# Frontend
cd frontend
npm install
npm run dev
```

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `DATABASE_URL` | PostgreSQL connection string | `postgresql+asyncpg://...` |
| `OLLAMA_HOST` | Ollama server URL | `http://ollama:11434` |

---

## ğŸ“„ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/auth/signup` | User registration |
| POST | `/auth/login` | User login (returns JWT) |
| GET | `/me` | Get current user profile |
| PUT | `/me` | Update user profile |
| POST | `/me/onboard` | Set initial preferences |
| GET | `/feed` | Get personalized article feed |
| GET | `/summary` | Get today's personalized summary |
| POST | `/interactions` | Record like/dislike |
| POST | `/ingest/run` | Trigger manual ingestion |

---

## ğŸ“š Documentation

Detailed documentation is available in the `/docs` directory:

- [System Architecture](docs/system_architecture.md) â€” Full architecture diagrams
- [Components](docs/components.md) â€” Entity and service descriptions
- [ERD](docs/erd.md) â€” Database entity relationships
- [Data Flow](docs/data_flow.md) â€” Data pipeline diagrams

---

## ğŸ“œ License

This project is licensed under the terms specified in the [LICENSE](LICENSE) file.